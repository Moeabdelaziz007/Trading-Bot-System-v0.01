"""
Intelligent Collaboration Engine for AlphaAxiom Learning Loop v2.0

This module implements enhanced multi-agent collaboration with dynamic 
weighting and conflict resolution for the AlphaAxiom trading system.
"""

import json
import numpy as np
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict


@dataclass
class AgentInsight:
    """Represents an insight generated by an agent"""
    agent_id: str
    insight_type: str  # 'signal', 'risk', 'strategy', 'pattern'
    content: Dict[str, Any]
    confidence: float
    timestamp: datetime
    context: Dict[str, Any]  # Market conditions when insight was generated
    metadata: Optional[Dict[str, Any]] = None


@dataclass
class CollaborationDecision:
    """Represents a collaborative decision made by multiple agents"""
    decision_id: str
    participants: List[str]
    final_action: str
    confidence: float
    reasoning: str
    timestamp: datetime
    expected_impact: float = 0.0


class IntelligentCollaborationEngine:
    """
    Enhanced multi-agent collaboration engine with dynamic weighting and 
    conflict resolution.
    
    This engine coordinates multiple AI agents in the AlphaAxiom system,
    facilitating collaborative decision-making based on insights from
    different specialized agents.
    """
    
    def __init__(self, d1_db, kv_store):
        """
        Initialize the collaboration engine.
        
        Args:
            d1_db: D1 database connection for persistent storage
            kv_store: KV store for fast access to collaboration data
        """
        self.d1 = d1_db
        self.kv = kv_store
        self.active_collaborations = {}
        self.agent_performance = {}
        self.consensus_history = []
        
        # Dynamic collaboration weights
        self.collaboration_weights = {
            'signal_sharing': 0.3,
            'risk_hedging': 0.25,
            'knowledge_transfer': 0.25,
            'strategy_sync': 0.2
        }
    
    async def initialize_agent(self, agent_id: str, agent_type: str) -> \
            Dict[str, Any]:
        """
        Initialize a new agent in the collaboration system.
        
        Args:
            agent_id: Unique identifier for the agent
            agent_type: Type of agent (e.g., 'analyst', 'strategist')
            
        Returns:
            Dictionary containing agent profile information
        """
        agent_profile = {
            'agent_id': agent_id,
            'type': agent_type,
            'expertise': self._determine_expertise(agent_type),
            'collaboration_score': 0.5,
            'trust_score': 0.5,
            'knowledge_contribution': 0,
            'successful_collaborations': 0,
            'last_active': datetime.now().isoformat()
        }
        
        await self.d1.execute(
            """
            INSERT OR REPLACE INTO learning_agents 
            (agent_id, agent_type, expertise, collaboration_score, 
             trust_score, knowledge_contribution,
             successful_collaborations, last_active)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """,
            agent_id, agent_type, json.dumps(agent_profile['expertise']),
            agent_profile['collaboration_score'], 
            agent_profile['trust_score'],
            agent_profile['knowledge_contribution'], 
            agent_profile['successful_collaborations'],
            agent_profile['last_active'])
        
        return agent_profile
    
    async def share_insight_with_context(self, insight: AgentInsight) -> \
            Dict[str, Any]:
        """
        Share an insight with full contextual information.
        
        Args:
            insight: AgentInsight object containing the insight to share
            
        Returns:
            Dictionary with insight sharing results
        """
        # 1. Analyze current market context
        market_context = await self._analyze_market_context(insight.context)
        
        # 2. Evaluate insight quality
        insight_score = self._evaluate_insight_quality(insight, market_context)
        
        # 3. Identify beneficiaries
        beneficiaries = await self._identify_beneficiaries(
            insight.insight_type, insight.agent_id, market_context
        )
        
        # 4. Store insight with all metadata
        insight_id = f"insight_{insight.agent_id}_" \
                     f"{int(datetime.now().timestamp())}"
        
        insight_data = {
            **asdict(insight),
            'market_context': market_context,
            'insight_score': insight_score,
            'beneficiaries': beneficiaries,
            'ttl': 86400  # 24 hours
        }
        
        await self.kv.put(insight_id, json.dumps(insight_data))
        
        # 5. Notify beneficiaries
        await self._notify_beneficiaries(insight_id, beneficiaries, 
                                         insight_data)
        
        # 6. Update agent performance
        await self._update_agent_performance(insight.agent_id, insight_score)
        
        return {
            'insight_id': insight_id,
            'score': insight_score,
            'beneficiaries': beneficiaries,
            'market_context': market_context
        }
    
    async def collaborative_decision_making(
            self, agents: List[str], problem: Dict[str, Any]
    ) -> CollaborationDecision:
        """
        Make an intelligent collaborative decision.
        
        Args:
            agents: List of agent IDs participating in the decision
            problem: Dictionary describing the problem to solve
            
        Returns:
            CollaborationDecision object with the final decision
        """
        # 1. Collect opinions from all agents
        agent_opinions = {}
        for agent_id in agents:
            opinion = await self._get_agent_opinion(agent_id, problem)
            if opinion:
                agent_opinions[agent_id] = opinion
        
        # 2. Apply intelligent consensus algorithm
        consensus = await self._intelligent_consensus(agent_opinions, problem)
        
        # 3. Resolve conflicts if needed
        if consensus['conflict_level'] > 0.3:
            resolved = await self._resolve_conflicts(agent_opinions, consensus)
            consensus = resolved
        
        # 4. Record decision
        decision = CollaborationDecision(
            decision_id=f"collab_{int(datetime.now().timestamp())}",
            participants=agents,
            final_action=consensus['final_action'],
            confidence=consensus['confidence'],
            reasoning=consensus['reasoning'],
            timestamp=datetime.now(),
            expected_impact=consensus['expected_impact']
        )
        
        # 5. Store in database
        await self._store_collaboration_decision(decision)
        
        # 6. Update collaboration scores
        await self._update_collaboration_scores(agents, decision)
        
        return decision
    
    async def _intelligent_consensus(self, opinions: Dict, 
                                     problem: Dict) -> Dict:
        """
        Apply intelligent consensus with conflict resolution.
        
        Args:
            opinions: Dictionary of agent opinions
            problem: Problem being solved
            
        Returns:
            Dictionary with consensus results
        """
        # 1. Dynamic weighting based on:
        #    - Historical agent performance
        #    - Expertise in current problem
        #    - Quality of reasoning
        
        weighted_votes: Dict[str, float] = {}
        total_weight: float = 0
        
        for agent_id, opinion in opinions.items():
            # Calculate agent weight
            agent_weight = await self._calculate_agent_weight(
                agent_id, problem, opinion)
            
            # Collect weighted votes for each action
            action = opinion['recommended_action']
            weighted_votes[action] = weighted_votes.get(action, 0) + \
                          agent_weight
            total_weight += agent_weight
            
            # Analyze reasoning quality
            reasoning_quality = self._analyze_reasoning_quality(
                opinion['reasoning'])
            
            if reasoning_quality > 0.8:
                # Boost vote weight for high-quality reasoning
                weighted_votes[action] += agent_weight * 0.2
        
        # 2. Determine winning action
        if not weighted_votes:
            return {
                'final_action': 'HOLD',
                'confidence': 0,
                'reasoning': 'No valid opinions',
                'expected_impact': 0,
                'conflict_level': 0
            }
        
        winning_action = max(weighted_votes.items(), key=lambda x: x[1])
        winning_votes = winning_action[1]
        confidence = winning_votes / total_weight if total_weight > 0 else 0
        
        # 3. Calculate conflict level
        conflict_level = self._calculate_conflict_level(weighted_votes, 
                                                        total_weight)
        
        # 4. Generate collective reasoning
        collective_reasoning = await self._generate_collective_reasoning(
            opinions, winning_action[0])
        
        return {
            'final_action': winning_action[0],
            'confidence': confidence,
            'reasoning': collective_reasoning,
            'expected_impact': await self._estimate_impact(winning_action[0], 
                                                           problem),
            'conflict_level': conflict_level
        }
    
    async def _calculate_agent_weight(
            self, agent_id: str, problem: Dict, opinion: Dict
    ) -> float:
        """
        Calculate dynamic agent weight.
        
        Args:
            agent_id: ID of the agent
            problem: Problem being solved
            opinion: Agent's opinion on the problem
            
        Returns:
            Float representing the agent's weight (0.1 to 2.0)
        """
        base_weight = 1.0
        
        # 1. Historical performance factor
        perf_data = await self.d1.execute(
            "SELECT success_rate, total_pnl FROM agent_performance "
            "WHERE agent_id = ?",
            agent_id
        )
        
        if perf_data:
            success_rate = perf_data[0]['success_rate'] or 0.5
            pnl_factor = min(1.0, abs(perf_data[0]['total_pnl'] or 0) / 1000)
            base_weight *= (0.3 + success_rate * 0.7) * (1 + pnl_factor * 0.2)
        
        # 2. Expertise match factor
        expertise_match = self._calculate_expertise_match(agent_id, problem)
        base_weight *= (0.5 + expertise_match * 0.5)
        
        # 3. Opinion confidence factor
        opinion_confidence = opinion.get('confidence', 0.5)
        base_weight *= (0.3 + opinion_confidence * 0.7)
        
        # 4. Collaboration factor
        collab_score = self.agent_performance.get(f"{agent_id}_collab", 0.5)
        base_weight *= (0.4 + collab_score * 0.6)
        
        return max(0.1, min(2.0, base_weight))
    
    def _calculate_conflict_level(
            self, weighted_votes: Dict, total_weight: float
    ) -> float:
        """
        Calculate conflict level between agent opinions.
        
        Args:
            weighted_votes: Dictionary of weighted votes
            total_weight: Total weight of all votes
            
        Returns:
            Float representing conflict level (0.0 to 1.0)
        """
        if total_weight == 0:
            return 0
        
        # Calculate Gini coefficient for inequality
        votes_list = list(weighted_votes.values())
        n = len(votes_list)
        if n <= 1:
            return 0
        
        sum_abs_diff = 0
        for i in range(n):
            for j in range(n):
                sum_abs_diff += abs(votes_list[i] - votes_list[j])
        
        gini = sum_abs_diff / (2 * n * n * np.mean(votes_list))
        return min(1.0, gini)
    
    async def _generate_collective_reasoning(
            self, opinions: Dict, winning_action: str
    ) -> str:
        """
        Generate collective reasoning from all opinions.
        
        Args:
            opinions: Dictionary of agent opinions
            winning_action: The action that won the consensus
            
        Returns:
            String with collective reasoning
        """
        winning_reasons = []
        alternative_reasons = []
        
        for agent_id, opinion in opinions.items():
            if opinion['recommended_action'] == winning_action:
                winning_reasons.append({
                    'agent': agent_id,
                    'reasoning': opinion['reasoning'],
                    'confidence': opinion['confidence']
                })
            else:
                alternative_reasons.append({
                    'agent': agent_id,
                    'action': opinion['recommended_action'],
                    'reasoning': opinion['reasoning']
                })
        
        # Build collective reasoning
        reasoning_parts = []
        
        if winning_reasons:
            top_reason = max(winning_reasons, key=lambda x: x['confidence'])
            reasoning_parts.append(
                f"Main decision ({winning_action}) based on: "
                f"{top_reason['reasoning']}")
            
            if len(winning_reasons) > 1:
                reasoning_parts.append(
                    f"Supported by {len(winning_reasons)-1} other agents")
        
        if alternative_reasons:
            reasoning_parts.append("Alternative views included:")
            for alt in alternative_reasons[:2]:  # Top 2 alternative views
                reasoning_parts.append(
                    f"- {alt['agent']}: {alt['action']} "
                    f"({alt['reasoning'][:50]}...)")
        
        return " ".join(reasoning_parts)
    
    def _determine_expertise(self, agent_type: str) -> List[str]:
        """
        Determine agent expertise based on agent type.
        
        Args:
            agent_type: Type of agent
            
        Returns:
            List of expertise areas
        """
        expertise_map = {
            'analyst': ['technical_analysis', 'pattern_recognition', 
                        'market_sentiment'],
            'strategist': ['risk_management', 'portfolio_optimization', 
                           'market_regime_detection'],
            'journalist': ['news_analysis', 'event_impact_assessment',
                           'social_sentiment'],
            'guardian': ['risk_assessment', 'position_sizing',
                         'stop_loss_calculation'],
            'collector': ['data_acquisition', 'market_data_processing',
                          'alternative_data_sources']
        }
        
        return expertise_map.get(agent_type, ['general_trading'])
    
    async def _analyze_market_context(self, context: Dict) -> Dict:
        """
        Analyze market context for an insight.
        
        Args:
            context: Market context dictionary
            
        Returns:
            Dictionary with market analysis
        """
        analysis = {
            'volatility_level': 'UNKNOWN',
            'trend_strength': 0,
            'market_regime': 'NEUTRAL',
            'risk_level': 'MEDIUM',
            'opportunity_score': 0.5
        }
        
        if 'indicators' in context:
            indicators = context['indicators']
            
            # Analyze volatility
            if 'atr' in indicators:
                atr_value = indicators['atr']
                if atr_value > 0.02:
                    analysis['volatility_level'] = 'HIGH'
                elif atr_value > 0.01:
                    analysis['volatility_level'] = 'MEDIUM'
                else:
                    analysis['volatility_level'] = 'LOW'
            
            # Analyze trend strength
            if 'rsi' in indicators:
                rsi_value = indicators['rsi']
                if isinstance(rsi_value, (int, float)):
                    analysis['trend_strength'] = abs(rsi_value - 50) / 50
                else:
                    analysis['trend_strength'] = 0
            
            # Determine market regime
            if (analysis['volatility_level'] == 'HIGH' and
                    isinstance(analysis['trend_strength'], (int, float)) and
                    analysis['trend_strength'] > 0.7):
                analysis['market_regime'] = 'TRENDING_VOLATILE'
            elif (analysis['volatility_level'] == 'LOW' and 
                  isinstance(analysis['trend_strength'], (int, float)) and
                  analysis['trend_strength'] < 0.3):
                analysis['market_regime'] = 'RANGING'
            
            # Calculate opportunity score
            trend_strength = analysis['trend_strength']
            if isinstance(trend_strength, (int, float)):
                analysis['opportunity_score'] = (
                    trend_strength * 0.6 +
                    (1 if analysis['volatility_level'] == 'MEDIUM'
                     else 0.5) * 0.4
                )
            else:
                analysis['opportunity_score'] = 0.5
        
        return analysis
    
    def _evaluate_insight_quality(
            self, insight: AgentInsight, market_context: Dict
    ) -> float:
        """
        Evaluate the quality of an insight.
        
        Args:
            insight: AgentInsight to evaluate
            market_context: Market context analysis
            
        Returns:
            Float representing insight quality (0.0 to 1.0)
        """
        # Base quality on confidence
        quality = insight.confidence
        
        # Adjust based on market context
        if market_context['volatility_level'] == 'HIGH':
            # High volatility increases value of good insights
            quality *= 1.2
        elif market_context['volatility_level'] == 'LOW':
            # Low volatility decreases value of insights
            quality *= 0.8
        
        # Adjust based on trend strength
        quality *= (0.8 + market_context['trend_strength'] * 0.4)
        
        return min(1.0, max(0.0, quality))
    
    async def _identify_beneficiaries(
            self, insight_type: str, agent_id: str, market_context: Dict
    ) -> List[str]:
        """
        Identify agents that would benefit from an insight.
        
        Args:
            insight_type: Type of insight
            agent_id: ID of agent that generated the insight
            market_context: Market context analysis
            
        Returns:
            List of beneficiary agent IDs
        """
        # In a full implementation, this would query the database to find
        # agents that would benefit from this type of insight
        # For now, we'll return a placeholder
        return ['analyst', 'strategist', 'guardian']
    
    async def _notify_beneficiaries(
            self, insight_id: str, beneficiaries: List[str], insight_data: Dict
    ) -> None:
        """
        Notify beneficiary agents of a new insight.
        
        Args:
            insight_id: ID of the insight
            beneficiaries: List of beneficiary agent IDs
            insight_data: Insight data to send
        """
        # In a full implementation, this would send notifications to the
        # beneficiary agents, possibly through a messaging system
        pass
    
    async def _update_agent_performance(
            self, agent_id: str, insight_score: float
    ) -> None:
        """
        Update agent performance metrics.
        
        Args:
            agent_id: ID of the agent
            insight_score: Score of the insight provided
        """
        # Update in-memory performance tracking
        current_score = self.agent_performance.get(agent_id, 0.5)
        # Simple moving average update
        new_score = (current_score * 0.9) + (insight_score * 0.1)
        self.agent_performance[agent_id] = new_score
        
        # Update in database
        await self.d1.execute(
            """
            UPDATE learning_agents 
            SET knowledge_contribution = knowledge_contribution + 1,
                last_active = ?
            WHERE agent_id = ?
            """,
            datetime.now().isoformat(), agent_id
        )
    
    async def _get_agent_opinion(
            self, agent_id: str, problem: Dict
    ) -> Optional[Dict]:
        """
        Get an agent's opinion on a problem.
        
        Args:
            agent_id: ID of the agent
            problem: Problem to get opinion on
            
        Returns:
            Dictionary with agent's opinion or None
        """
        # In a full implementation, this would query the agent for its opinion
        # For now, we'll return a placeholder
        return {
            'agent_id': agent_id,
            'recommended_action': 'BUY',
            'confidence': 0.75,
            'reasoning': f'Based on analysis of '
                         f'{problem.get("symbol", "unknown")} '
                         f'market conditions',
            'timestamp': datetime.now().isoformat()
        }
    
    def _analyze_reasoning_quality(self, reasoning: str) -> float:
        """
        Analyze the quality of reasoning.
        
        Args:
            reasoning: Reasoning string to analyze
            
        Returns:
            Float representing reasoning quality (0.0 to 1.0)
        """
        # Simple heuristic: longer reasoning with more detail is better
        # In a full implementation, this could use NLP analysis
        word_count = len(reasoning.split())
        quality = min(1.0, word_count / 20.0)  # Assume 20 words is good
        return quality
    
    async def _resolve_conflicts(
            self, opinions: Dict, consensus: Dict
    ) -> Dict:
        """
        Resolve conflicts between agent opinions.
        
        Args:
            opinions: Dictionary of agent opinions
            consensus: Current consensus results
            
        Returns:
            Dictionary with conflict resolution results
        """
        # In a full implementation, this would implement conflict 
        # resolution logic
        # For now, we'll return the original consensus
        return consensus
    
    async def _estimate_impact(self, action: str, problem: Dict) -> float:
        """
        Estimate the expected impact of an action.
        
        Args:
            action: Action to estimate impact for
            problem: Problem being solved
            
        Returns:
            Float representing expected impact (-1.0 to 1.0)
        """
        # In a full implementation, this would estimate the impact
        # For now, we'll return a placeholder
        impact_map = {
            'BUY': 0.1,
            'SELL': -0.1,
            'HOLD': 0.0
        }
        return impact_map.get(action, 0.0)
    
    async def _store_collaboration_decision(
            self, decision: CollaborationDecision
    ) -> None:
        """
        Store a collaboration decision in the database.
        
        Args:
            decision: CollaborationDecision to store
        """
        await self.d1.execute(
            """
            INSERT INTO collaboration_decisions 
            (decision_id, participants, final_action, confidence, reasoning, 
             timestamp, expected_impact)
            VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
            decision.decision_id, json.dumps(decision.participants), 
            decision.final_action, decision.confidence, decision.reasoning, 
            decision.timestamp.isoformat(), decision.expected_impact
        )
    
    async def _update_collaboration_scores(
            self, agents: List[str], decision: CollaborationDecision
    ) -> None:
        """
        Update collaboration scores for participating agents.
        
        Args:
            agents: List of agent IDs
            decision: CollaborationDecision that was made
        """
        for agent_id in agents:
            # Update collaboration score
            current_score = self.agent_performance.get(
                f"{agent_id}_collab", 0.5)
            
            if decision.confidence > 0.7:
                # Reward participation in high-confidence decisions
                new_score = min(1.0, current_score + 0.05)
            else:
                # Small adjustment for low-confidence decisions
                new_score = max(0.1, current_score - 0.01)
            
            self.agent_performance[f"{agent_id}_collab"] = new_score
            
            # Update in database
            await self.d1.execute(
                """
                UPDATE learning_agents 
                SET collaboration_score = ?, 
                    successful_collaborations = successful_collaborations + 1,
                    last_active = ?
                WHERE agent_id = ?
                """,
                new_score, datetime.now().isoformat(), agent_id
            )
    
    def _calculate_expertise_match(
            self, agent_id: str, problem: Dict
    ) -> float:
        """
        Calculate how well an agent's expertise matches a problem.
        
        Args:
            agent_id: ID of the agent
            problem: Problem to match against
            
        Returns:
            Float representing expertise match (0.0 to 1.0)
        """
        # In a full implementation, this would compare the agent's expertise
        # with the requirements of the problem
        # For now, we'll return a placeholder
        return 0.75